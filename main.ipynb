{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils #for resizing\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import time\n",
    "from scipy.spatial import distance as dist #euclidian distance\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_csv(csv_file, csv_columns, dict_data):\n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            #writer.writeheader()\n",
    "            for key, value in dict_data.items():\n",
    "                writer.writerow({'name': key, 'face_data': value})\n",
    "    except IOError:\n",
    "        print(\"I/O error\", csv_file)\n",
    "    return\n",
    "def append_to_csv(csvfile, data):\n",
    "    with open(csvfile, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for key, value in data.items():\n",
    "            writer.writerow([key,value])\n",
    "    return\n",
    "def cvt_to_array(data, split_with=''):\n",
    "    if split_with == '':\n",
    "        return np.array(list(map(float, data)))\n",
    "    else:\n",
    "        return np.array(list(map(float, data.split(split_with))))\n",
    "csv_columns = ['name', 'face_data']\n",
    "csv_file = 'all_face_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data = []\n",
    "labels = []\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() # detect the faces in the image. How many faces are there\n",
    "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat') # predict the face landmarks such as mouth or eyes\n",
    "#(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"] \n",
    "#(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "facerec = dlib.face_recognition_model_v1('./dlib_face_recognition_resnet_model_v1.dat') #pretrained model. \n",
    "#we send the data to this function and it returns a 128D vector that described the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please show your whole face to camera. When the face is detected, you will be asked for the name.\n",
      "who is thisdr dre\n",
      "File already exist, data is appended to file\n"
     ]
    }
   ],
   "source": [
    "#capture the person and save as the 128D vector\n",
    "# this part captures only once\n",
    "cap = cv2.VideoCapture(0)\n",
    "#while True:\n",
    "\n",
    "face_number = 0\n",
    "while face_number == 0:\n",
    "    print('Please show your whole face to camera. When the face is detected, you will be asked for the name.')\n",
    "    time.sleep(0.5)\n",
    "    ret, image = cap.read()\n",
    "    image = imutils.resize(image, width=500) #resizing\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #it should convert to gray in onder to improve resultt.\n",
    "    rects = detector(gray, 0) # detect how many faces in the image\n",
    "    cv2.imshow('asd', gray)\n",
    "    for (i, rect) in enumerate(rects): \n",
    "        # for every faces\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect) # predict the face landmarks in image. \n",
    "\n",
    "        face_descriptor = facerec.compute_face_descriptor(image, shape) # send the shape data to resnet model. it returns a 128D vector\n",
    "        \n",
    "        while face_descriptor == -1:\n",
    "            print('Face not found.')\n",
    "        else:\n",
    "            face_data.append(face_descriptor) # save the face data to array\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "            name = raw_input('who is this')\n",
    "            labels.append(name)\n",
    "            data[labels[0]] = face_data[0]\n",
    "            face_data=[]\n",
    "            labels=[]\n",
    "            my_file = Path(\"./\" + csv_file)\n",
    "            if my_file.is_file():\n",
    "                append_to_csv(csv_file, data)\n",
    "                print('File already exist, data is appended to file')\n",
    "            else:\n",
    "                write_dict_to_csv(csv_file, csv_columns, data)    \n",
    "                print('File has been created and data saved to file.')\n",
    "            face_number += 1\n",
    "        #print(face_descriptor)\n",
    "        '''\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(image, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(image, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        ''' \n",
    "cv2.imshow(\"Saved face\", image)\n",
    "cv2.waitKey(0)\n",
    "#key = cv2.waitKey(1) & 0xFF\n",
    "#break\n",
    "# if the `q` key was pressed, break from the loopfurka\n",
    "#if key == ord(\"q\"):\n",
    "#    break\n",
    "#time.sleep(0.5)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is actually real time working part. It calcuates the same data as the previous part.\n",
    "# and it calculates euclidian distance for every faces. If any calculations is less than 0.55 then it means we found faces\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    image = imutils.resize(image, width=200)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect)\n",
    "        \n",
    "        trying = np.array(facerec.compute_face_descriptor(image, shape))\n",
    "        #distance_faces = dist.euclidean(face_data, trying)\n",
    "    \n",
    "        with open('./'+csv_file, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if row == [] or row[1] == \"face_data\":\n",
    "                    continue\n",
    "                else:\n",
    "                    #row[1] = np.array(list(map(float, row[1].split('\\n'))))\n",
    "                    row[1] = cvt_to_array(row[1], '\\n')\n",
    "                    trying = cvt_to_array(trying)\n",
    "                    distance_faces = dist.euclidean(row[1], trying)\n",
    "                    if distance_faces < 0.55:\n",
    "                        content = row[0]\n",
    "                        break\n",
    "                    else:\n",
    "                        content = \"unknown\"\n",
    "                    \n",
    "        cv2.putText(image,content, (10,40), cv2.FONT_HERSHEY_PLAIN, 1, 255)\n",
    "        \n",
    "        \n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "        #print(distance_faces)\n",
    "        '''if distance_faces < 0.55:\n",
    "            cv2.putText(image,\"furkan\", (10,20), cv2.FONT_HERSHEY_PLAIN, 1, 255)\n",
    "        else:\n",
    "            cv2.putText(image,\"unknown\", (10,20), cv2.FONT_HERSHEY_PLAIN, 1, 255)\n",
    "        \n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(image, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(image, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    #break\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
